{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Machine Learning Practice "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Informations\n",
    "\n",
    "- Dataset: Music dataset\n",
    "\n",
    "- Objectives: Classification\n",
    "\n",
    "- Time Limits: 1 min\n",
    "\n",
    "- Score: Classification Accuracy (Test Data)\n",
    "\n",
    "- Please read all markdowns carefully \n",
    "\n",
    "- About Dataset: Music Style Data\n",
    "    - 348 float type music features (frequency, tone, tempo, timbre...)\n",
    "    - Label: Music Style\n",
    "        - 1: Melancholy\n",
    "        - 2: Romantic\n",
    "        - 3: Rhythmical\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Step 0] Importing Packages\n",
    "\n",
    "You must specify all the packages you use in this practice in the cell below.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-24T17:39:25.142951Z",
     "start_time": "2021-09-24T17:39:18.604715Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "data_path = ['data']\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, MaxAbsScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, balanced_accuracy_score, f1_score, recall_score, precision_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Step 1] Read Data\n",
    "\n",
    "Train dataset is in the 'data' directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-24T17:39:25.235951Z",
     "start_time": "2021-09-24T17:39:25.146960Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Import the data using the file path\n",
    "filepath = os.sep.join(data_path + ['music_train_data.csv'])\n",
    "data = pd.read_csv(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-24T17:39:27.802971Z",
     "start_time": "2021-09-24T17:39:25.239953Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>f10</th>\n",
       "      <th>...</th>\n",
       "      <th>f340</th>\n",
       "      <th>f341</th>\n",
       "      <th>f342</th>\n",
       "      <th>f343</th>\n",
       "      <th>f344</th>\n",
       "      <th>f345</th>\n",
       "      <th>f346</th>\n",
       "      <th>f347</th>\n",
       "      <th>f348</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.166614</td>\n",
       "      <td>0.284691</td>\n",
       "      <td>-0.011022</td>\n",
       "      <td>-1.028812</td>\n",
       "      <td>0.101653</td>\n",
       "      <td>0.498247</td>\n",
       "      <td>-0.314566</td>\n",
       "      <td>1.208697</td>\n",
       "      <td>-1.503008</td>\n",
       "      <td>-1.457764</td>\n",
       "      <td>...</td>\n",
       "      <td>2.136721</td>\n",
       "      <td>-1.193955</td>\n",
       "      <td>0.040614</td>\n",
       "      <td>1.127366</td>\n",
       "      <td>0.741521</td>\n",
       "      <td>-0.70773</td>\n",
       "      <td>0.077748</td>\n",
       "      <td>0.832992</td>\n",
       "      <td>-1.291423</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 349 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         f1        f2        f3        f4        f5        f6        f7  \\\n",
       "0 -0.166614  0.284691 -0.011022 -1.028812  0.101653  0.498247 -0.314566   \n",
       "\n",
       "         f8        f9       f10  ...      f340      f341      f342      f343  \\\n",
       "0  1.208697 -1.503008 -1.457764  ...  2.136721 -1.193955  0.040614  1.127366   \n",
       "\n",
       "       f344     f345      f346      f347      f348  answer  \n",
       "0  0.741521 -0.70773  0.077748  0.832992 -1.291423       2  \n",
       "\n",
       "[1 rows x 349 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-24T17:39:27.834972Z",
     "start_time": "2021-09-24T17:39:27.822969Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(650, 349)\n",
      "f1        float64\n",
      "f2        float64\n",
      "f3        float64\n",
      "f4        float64\n",
      "f5        float64\n",
      "           ...   \n",
      "f345      float64\n",
      "f346      float64\n",
      "f347      float64\n",
      "f348      float64\n",
      "answer      int64\n",
      "Length: 349, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data.columns[:-1]\n",
    "X_data = data[features]\n",
    "y_data = data['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    0.516923\n",
      "2    0.369231\n",
      "3    0.113846\n",
      "Name: answer, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Label proportion => imbalanced!\n",
    "print(y_data.value_counts(normalize=True).sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Step 2] Data Preprocessing\n",
    "\n",
    "* Generate various dataset with combination of various preprocessing\n",
    "* First, calculate each feature columns' correlation with other columns, generate new dataset with high correlation feature columns dropped\n",
    "* Second, generate dataset with MinMaxScaler, StandardScaler\n",
    "* Third, for MinMax scaled data, check skewing of each columns, and generate new dataset with applying log to columns with high skew values\n",
    "* Generated datasets are \n",
    "1. original-data\n",
    "2. dropped-data\n",
    "3. minmaxscaled-data \n",
    "4. standardscaled-data\n",
    "5. minmaxscaled-skewlogged-data\n",
    "6. minmaxscaled-dropped-data\n",
    "7. standardscaled-dropped-data\n",
    "8. minmaxscaled-skewlogged-dropped-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision trees and ensemble methods do not require feature scaling to be performed \n",
    "# they are not sensitive to the the variance in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store various experimental training dataset\n",
    "X_data_dict = {'X_data': X_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>f10</th>\n",
       "      <th>...</th>\n",
       "      <th>f339</th>\n",
       "      <th>f340</th>\n",
       "      <th>f341</th>\n",
       "      <th>f342</th>\n",
       "      <th>f343</th>\n",
       "      <th>f344</th>\n",
       "      <th>f345</th>\n",
       "      <th>f346</th>\n",
       "      <th>f347</th>\n",
       "      <th>f348</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f2</th>\n",
       "      <td>0.986154</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f3</th>\n",
       "      <td>0.141059</td>\n",
       "      <td>0.137554</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f4</th>\n",
       "      <td>0.338368</td>\n",
       "      <td>0.352530</td>\n",
       "      <td>0.067998</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f5</th>\n",
       "      <td>0.675279</td>\n",
       "      <td>0.678184</td>\n",
       "      <td>0.110398</td>\n",
       "      <td>0.435819</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f344</th>\n",
       "      <td>0.401183</td>\n",
       "      <td>0.392504</td>\n",
       "      <td>0.294139</td>\n",
       "      <td>0.048916</td>\n",
       "      <td>0.070123</td>\n",
       "      <td>0.172394</td>\n",
       "      <td>0.196303</td>\n",
       "      <td>0.687886</td>\n",
       "      <td>0.006476</td>\n",
       "      <td>0.361006</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005967</td>\n",
       "      <td>0.017944</td>\n",
       "      <td>0.041522</td>\n",
       "      <td>0.080583</td>\n",
       "      <td>0.693674</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f345</th>\n",
       "      <td>0.203257</td>\n",
       "      <td>0.198477</td>\n",
       "      <td>0.352966</td>\n",
       "      <td>0.029907</td>\n",
       "      <td>0.032824</td>\n",
       "      <td>0.302407</td>\n",
       "      <td>0.054753</td>\n",
       "      <td>0.263086</td>\n",
       "      <td>0.037035</td>\n",
       "      <td>0.213334</td>\n",
       "      <td>...</td>\n",
       "      <td>0.132826</td>\n",
       "      <td>0.020030</td>\n",
       "      <td>0.077922</td>\n",
       "      <td>0.010812</td>\n",
       "      <td>0.333309</td>\n",
       "      <td>0.364506</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f346</th>\n",
       "      <td>0.028590</td>\n",
       "      <td>0.024365</td>\n",
       "      <td>0.026298</td>\n",
       "      <td>0.019282</td>\n",
       "      <td>0.209997</td>\n",
       "      <td>0.014193</td>\n",
       "      <td>0.014462</td>\n",
       "      <td>0.214913</td>\n",
       "      <td>0.004694</td>\n",
       "      <td>0.174357</td>\n",
       "      <td>...</td>\n",
       "      <td>0.078074</td>\n",
       "      <td>0.143545</td>\n",
       "      <td>0.069250</td>\n",
       "      <td>0.014253</td>\n",
       "      <td>0.065581</td>\n",
       "      <td>0.139374</td>\n",
       "      <td>0.051037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f347</th>\n",
       "      <td>0.282348</td>\n",
       "      <td>0.297530</td>\n",
       "      <td>0.200277</td>\n",
       "      <td>0.197937</td>\n",
       "      <td>0.574398</td>\n",
       "      <td>0.089421</td>\n",
       "      <td>0.377089</td>\n",
       "      <td>0.454674</td>\n",
       "      <td>0.129858</td>\n",
       "      <td>0.467068</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026722</td>\n",
       "      <td>0.078784</td>\n",
       "      <td>0.035134</td>\n",
       "      <td>0.036331</td>\n",
       "      <td>0.769421</td>\n",
       "      <td>0.261522</td>\n",
       "      <td>0.113366</td>\n",
       "      <td>0.031478</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f348</th>\n",
       "      <td>0.028234</td>\n",
       "      <td>0.030185</td>\n",
       "      <td>0.152879</td>\n",
       "      <td>0.002750</td>\n",
       "      <td>0.009982</td>\n",
       "      <td>0.264144</td>\n",
       "      <td>0.032552</td>\n",
       "      <td>0.029729</td>\n",
       "      <td>0.029550</td>\n",
       "      <td>0.013561</td>\n",
       "      <td>...</td>\n",
       "      <td>0.141938</td>\n",
       "      <td>0.042446</td>\n",
       "      <td>0.021951</td>\n",
       "      <td>0.056636</td>\n",
       "      <td>0.038245</td>\n",
       "      <td>0.040368</td>\n",
       "      <td>0.472820</td>\n",
       "      <td>0.049649</td>\n",
       "      <td>0.118038</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>348 rows Ã— 348 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            f1        f2        f3        f4        f5        f6        f7  \\\n",
       "f1    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "f2    0.986154  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "f3    0.141059  0.137554  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "f4    0.338368  0.352530  0.067998  0.000000  0.000000  0.000000  0.000000   \n",
       "f5    0.675279  0.678184  0.110398  0.435819  0.000000  0.000000  0.000000   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "f344  0.401183  0.392504  0.294139  0.048916  0.070123  0.172394  0.196303   \n",
       "f345  0.203257  0.198477  0.352966  0.029907  0.032824  0.302407  0.054753   \n",
       "f346  0.028590  0.024365  0.026298  0.019282  0.209997  0.014193  0.014462   \n",
       "f347  0.282348  0.297530  0.200277  0.197937  0.574398  0.089421  0.377089   \n",
       "f348  0.028234  0.030185  0.152879  0.002750  0.009982  0.264144  0.032552   \n",
       "\n",
       "            f8        f9       f10  ...      f339      f340      f341  \\\n",
       "f1    0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "f2    0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "f3    0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "f4    0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "f5    0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "f344  0.687886  0.006476  0.361006  ...  0.005967  0.017944  0.041522   \n",
       "f345  0.263086  0.037035  0.213334  ...  0.132826  0.020030  0.077922   \n",
       "f346  0.214913  0.004694  0.174357  ...  0.078074  0.143545  0.069250   \n",
       "f347  0.454674  0.129858  0.467068  ...  0.026722  0.078784  0.035134   \n",
       "f348  0.029729  0.029550  0.013561  ...  0.141938  0.042446  0.021951   \n",
       "\n",
       "          f342      f343      f344      f345      f346      f347  f348  \n",
       "f1    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   0.0  \n",
       "f2    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   0.0  \n",
       "f3    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   0.0  \n",
       "f4    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   0.0  \n",
       "f5    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   0.0  \n",
       "...        ...       ...       ...       ...       ...       ...   ...  \n",
       "f344  0.080583  0.693674  0.000000  0.000000  0.000000  0.000000   0.0  \n",
       "f345  0.010812  0.333309  0.364506  0.000000  0.000000  0.000000   0.0  \n",
       "f346  0.014253  0.065581  0.139374  0.051037  0.000000  0.000000   0.0  \n",
       "f347  0.036331  0.769421  0.261522  0.113366  0.031478  0.000000   0.0  \n",
       "f348  0.056636  0.038245  0.040368  0.472820  0.049649  0.118038   0.0  \n",
       "\n",
       "[348 rows x 348 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Correlation between every feature columns\n",
    "X_data_corr = pd.DataFrame(index=X_data.columns, columns=X_data.columns)\n",
    "for col in X_data.columns:\n",
    "    X_data_corr[col] = X_data[X_data.columns].corrwith(X_data[col])\n",
    "for i in range(len(X_data_corr.columns)):\n",
    "    X_data_corr.iloc[i,i:] = 0.\n",
    "X_data_corr = X_data_corr.apply(abs)\n",
    "X_data_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['f1', 'f14', 'f17', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f29', 'f30', 'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f39', 'f41', 'f45', 'f47', 'f48', 'f49', 'f50', 'f51', 'f54', 'f55', 'f59', 'f65', 'f66', 'f77', 'f166', 'f167', 'f168', 'f169', 'f170', 'f171', 'f172', 'f173', 'f174', 'f175', 'f176', 'f177', 'f178', 'f205', 'f206', 'f207', 'f208', 'f209', 'f210', 'f211', 'f212', 'f213', 'f214', 'f215', 'f216', 'f217', 'f218', 'f219', 'f220', 'f221', 'f222', 'f223', 'f224', 'f225', 'f226', 'f227', 'f228', 'f229', 'f230', 'f245', 'f246', 'f247', 'f248', 'f249', 'f250', 'f251', 'f252', 'f253', 'f254', 'f255', 'f283', 'f284', 'f285', 'f286', 'f287', 'f288', 'f289', 'f290', 'f291', 'f292', 'f293', 'f294', 'f316', 'f322', 'f323', 'f324', 'f325']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>f10</th>\n",
       "      <th>f11</th>\n",
       "      <th>...</th>\n",
       "      <th>f339</th>\n",
       "      <th>f340</th>\n",
       "      <th>f341</th>\n",
       "      <th>f342</th>\n",
       "      <th>f343</th>\n",
       "      <th>f344</th>\n",
       "      <th>f345</th>\n",
       "      <th>f346</th>\n",
       "      <th>f347</th>\n",
       "      <th>f348</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.284691</td>\n",
       "      <td>-0.011022</td>\n",
       "      <td>-1.028812</td>\n",
       "      <td>0.101653</td>\n",
       "      <td>0.498247</td>\n",
       "      <td>-0.314566</td>\n",
       "      <td>1.208697</td>\n",
       "      <td>-1.503008</td>\n",
       "      <td>-1.457764</td>\n",
       "      <td>0.330351</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.196257</td>\n",
       "      <td>2.136721</td>\n",
       "      <td>-1.193955</td>\n",
       "      <td>0.040614</td>\n",
       "      <td>1.127366</td>\n",
       "      <td>0.741521</td>\n",
       "      <td>-0.707730</td>\n",
       "      <td>0.077748</td>\n",
       "      <td>0.832992</td>\n",
       "      <td>-1.291423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.651829</td>\n",
       "      <td>-1.754836</td>\n",
       "      <td>-0.512545</td>\n",
       "      <td>-1.063596</td>\n",
       "      <td>1.434039</td>\n",
       "      <td>-1.404162</td>\n",
       "      <td>-0.745222</td>\n",
       "      <td>0.054440</td>\n",
       "      <td>0.153028</td>\n",
       "      <td>-0.404961</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012412</td>\n",
       "      <td>-0.803444</td>\n",
       "      <td>-0.327357</td>\n",
       "      <td>1.022505</td>\n",
       "      <td>-1.083422</td>\n",
       "      <td>-0.714399</td>\n",
       "      <td>-1.407135</td>\n",
       "      <td>0.846917</td>\n",
       "      <td>-1.562645</td>\n",
       "      <td>0.365577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.353967</td>\n",
       "      <td>0.749125</td>\n",
       "      <td>-0.123296</td>\n",
       "      <td>-0.809340</td>\n",
       "      <td>0.042847</td>\n",
       "      <td>-0.688971</td>\n",
       "      <td>-0.741502</td>\n",
       "      <td>0.059323</td>\n",
       "      <td>0.995969</td>\n",
       "      <td>0.382129</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.324741</td>\n",
       "      <td>0.423848</td>\n",
       "      <td>-0.200293</td>\n",
       "      <td>-0.265410</td>\n",
       "      <td>-1.182842</td>\n",
       "      <td>-0.416810</td>\n",
       "      <td>0.234092</td>\n",
       "      <td>-1.061020</td>\n",
       "      <td>-1.595486</td>\n",
       "      <td>-0.867771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.151251</td>\n",
       "      <td>1.017266</td>\n",
       "      <td>-0.809429</td>\n",
       "      <td>-0.558230</td>\n",
       "      <td>-0.649047</td>\n",
       "      <td>-0.790528</td>\n",
       "      <td>-0.798548</td>\n",
       "      <td>1.471307</td>\n",
       "      <td>0.045307</td>\n",
       "      <td>1.159451</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214091</td>\n",
       "      <td>0.601954</td>\n",
       "      <td>-0.092321</td>\n",
       "      <td>-1.319499</td>\n",
       "      <td>-0.673082</td>\n",
       "      <td>-0.816716</td>\n",
       "      <td>-4.172430</td>\n",
       "      <td>1.093709</td>\n",
       "      <td>1.106629</td>\n",
       "      <td>0.476974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.761447</td>\n",
       "      <td>0.138536</td>\n",
       "      <td>2.406821</td>\n",
       "      <td>0.735203</td>\n",
       "      <td>-0.058044</td>\n",
       "      <td>0.358249</td>\n",
       "      <td>1.027844</td>\n",
       "      <td>-0.043828</td>\n",
       "      <td>-1.221248</td>\n",
       "      <td>0.532904</td>\n",
       "      <td>...</td>\n",
       "      <td>0.218412</td>\n",
       "      <td>-0.673082</td>\n",
       "      <td>-0.100535</td>\n",
       "      <td>-0.623208</td>\n",
       "      <td>1.571379</td>\n",
       "      <td>0.270780</td>\n",
       "      <td>-0.792427</td>\n",
       "      <td>-0.402796</td>\n",
       "      <td>1.349432</td>\n",
       "      <td>0.174976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>0.244564</td>\n",
       "      <td>2.173754</td>\n",
       "      <td>0.034836</td>\n",
       "      <td>0.180263</td>\n",
       "      <td>-2.834412</td>\n",
       "      <td>-0.392688</td>\n",
       "      <td>0.684052</td>\n",
       "      <td>-0.745517</td>\n",
       "      <td>0.918739</td>\n",
       "      <td>-1.070555</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.203314</td>\n",
       "      <td>-0.796906</td>\n",
       "      <td>0.086825</td>\n",
       "      <td>-1.014114</td>\n",
       "      <td>0.221252</td>\n",
       "      <td>0.200125</td>\n",
       "      <td>-0.153418</td>\n",
       "      <td>1.596107</td>\n",
       "      <td>0.641362</td>\n",
       "      <td>1.504907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>-0.940471</td>\n",
       "      <td>-0.717929</td>\n",
       "      <td>0.888751</td>\n",
       "      <td>0.787062</td>\n",
       "      <td>0.897648</td>\n",
       "      <td>1.208942</td>\n",
       "      <td>-0.863827</td>\n",
       "      <td>0.117906</td>\n",
       "      <td>0.355986</td>\n",
       "      <td>1.415710</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.152532</td>\n",
       "      <td>-0.746864</td>\n",
       "      <td>-0.600670</td>\n",
       "      <td>-1.552048</td>\n",
       "      <td>-0.825841</td>\n",
       "      <td>-0.372074</td>\n",
       "      <td>0.319805</td>\n",
       "      <td>-0.981512</td>\n",
       "      <td>-0.956493</td>\n",
       "      <td>0.741365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>-0.970338</td>\n",
       "      <td>-0.388963</td>\n",
       "      <td>-0.555268</td>\n",
       "      <td>0.342415</td>\n",
       "      <td>0.414480</td>\n",
       "      <td>0.010077</td>\n",
       "      <td>-0.959610</td>\n",
       "      <td>-0.218170</td>\n",
       "      <td>0.607368</td>\n",
       "      <td>0.265552</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.126745</td>\n",
       "      <td>-0.768960</td>\n",
       "      <td>-1.382635</td>\n",
       "      <td>0.147514</td>\n",
       "      <td>-0.699404</td>\n",
       "      <td>-1.162207</td>\n",
       "      <td>1.279939</td>\n",
       "      <td>0.647133</td>\n",
       "      <td>0.191886</td>\n",
       "      <td>0.421133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>-0.186426</td>\n",
       "      <td>-0.949760</td>\n",
       "      <td>-1.151156</td>\n",
       "      <td>-0.052513</td>\n",
       "      <td>0.516760</td>\n",
       "      <td>0.909057</td>\n",
       "      <td>-0.147741</td>\n",
       "      <td>-0.781873</td>\n",
       "      <td>-0.224130</td>\n",
       "      <td>-0.345255</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.536003</td>\n",
       "      <td>0.103654</td>\n",
       "      <td>1.257128</td>\n",
       "      <td>0.111375</td>\n",
       "      <td>-1.456077</td>\n",
       "      <td>-1.084994</td>\n",
       "      <td>-0.250769</td>\n",
       "      <td>-1.140101</td>\n",
       "      <td>-0.592954</td>\n",
       "      <td>0.498912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>1.647698</td>\n",
       "      <td>0.714630</td>\n",
       "      <td>-0.383750</td>\n",
       "      <td>-2.896258</td>\n",
       "      <td>0.363108</td>\n",
       "      <td>0.557782</td>\n",
       "      <td>-0.665291</td>\n",
       "      <td>0.035565</td>\n",
       "      <td>0.505658</td>\n",
       "      <td>-0.271610</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039215</td>\n",
       "      <td>-0.821553</td>\n",
       "      <td>-0.290509</td>\n",
       "      <td>-1.151889</td>\n",
       "      <td>-0.344792</td>\n",
       "      <td>-0.159026</td>\n",
       "      <td>-0.595187</td>\n",
       "      <td>0.742030</td>\n",
       "      <td>-0.136604</td>\n",
       "      <td>1.485533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>650 rows Ã— 248 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           f2        f3        f4        f5        f6        f7        f8  \\\n",
       "0    0.284691 -0.011022 -1.028812  0.101653  0.498247 -0.314566  1.208697   \n",
       "1    0.651829 -1.754836 -0.512545 -1.063596  1.434039 -1.404162 -0.745222   \n",
       "2    0.353967  0.749125 -0.123296 -0.809340  0.042847 -0.688971 -0.741502   \n",
       "3    0.151251  1.017266 -0.809429 -0.558230 -0.649047 -0.790528 -0.798548   \n",
       "4   -0.761447  0.138536  2.406821  0.735203 -0.058044  0.358249  1.027844   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "645  0.244564  2.173754  0.034836  0.180263 -2.834412 -0.392688  0.684052   \n",
       "646 -0.940471 -0.717929  0.888751  0.787062  0.897648  1.208942 -0.863827   \n",
       "647 -0.970338 -0.388963 -0.555268  0.342415  0.414480  0.010077 -0.959610   \n",
       "648 -0.186426 -0.949760 -1.151156 -0.052513  0.516760  0.909057 -0.147741   \n",
       "649  1.647698  0.714630 -0.383750 -2.896258  0.363108  0.557782 -0.665291   \n",
       "\n",
       "           f9       f10       f11  ...      f339      f340      f341  \\\n",
       "0   -1.503008 -1.457764  0.330351  ... -0.196257  2.136721 -1.193955   \n",
       "1    0.054440  0.153028 -0.404961  ...  0.012412 -0.803444 -0.327357   \n",
       "2    0.059323  0.995969  0.382129  ... -1.324741  0.423848 -0.200293   \n",
       "3    1.471307  0.045307  1.159451  ...  0.214091  0.601954 -0.092321   \n",
       "4   -0.043828 -1.221248  0.532904  ...  0.218412 -0.673082 -0.100535   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "645 -0.745517  0.918739 -1.070555  ... -0.203314 -0.796906  0.086825   \n",
       "646  0.117906  0.355986  1.415710  ... -0.152532 -0.746864 -0.600670   \n",
       "647 -0.218170  0.607368  0.265552  ... -0.126745 -0.768960 -1.382635   \n",
       "648 -0.781873 -0.224130 -0.345255  ... -0.536003  0.103654  1.257128   \n",
       "649  0.035565  0.505658 -0.271610  ...  0.039215 -0.821553 -0.290509   \n",
       "\n",
       "         f342      f343      f344      f345      f346      f347      f348  \n",
       "0    0.040614  1.127366  0.741521 -0.707730  0.077748  0.832992 -1.291423  \n",
       "1    1.022505 -1.083422 -0.714399 -1.407135  0.846917 -1.562645  0.365577  \n",
       "2   -0.265410 -1.182842 -0.416810  0.234092 -1.061020 -1.595486 -0.867771  \n",
       "3   -1.319499 -0.673082 -0.816716 -4.172430  1.093709  1.106629  0.476974  \n",
       "4   -0.623208  1.571379  0.270780 -0.792427 -0.402796  1.349432  0.174976  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "645 -1.014114  0.221252  0.200125 -0.153418  1.596107  0.641362  1.504907  \n",
       "646 -1.552048 -0.825841 -0.372074  0.319805 -0.981512 -0.956493  0.741365  \n",
       "647  0.147514 -0.699404 -1.162207  1.279939  0.647133  0.191886  0.421133  \n",
       "648  0.111375 -1.456077 -1.084994 -0.250769 -1.140101 -0.592954  0.498912  \n",
       "649 -1.151889 -0.344792 -0.159026 -0.595187  0.742030 -0.136604  1.485533  \n",
       "\n",
       "[650 rows x 248 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate new dataset by dropping columns with correlation value equal or larger than threshold(0.8)\n",
    "X_data_drop = X_data.copy()\n",
    "drop_col = []\n",
    "for col in X_data_corr.columns:\n",
    "    for row in X_data_corr.index:\n",
    "        if X_data_corr[col][row] >= 0.8:\n",
    "            X_data_drop.drop(columns=col, inplace=True)\n",
    "            drop_col.append(col)\n",
    "            break\n",
    "X_data_dict['X_data_drop'] = X_data_drop\n",
    "print(drop_col)\n",
    "X_data_drop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Step 3] Model Training\n",
    "\n",
    "* First, train single decision tree classifier without any parameter to obtain max depth and length of feature importances. With each dataset, using decision tree classifier, gridsearch parameters max_depth, max_features, with scoring method balanced accuracy and 5-fold stratified k fold cross validation\n",
    "* Second, for number of trees increasing from 15 to 500, calculate oob errors for bagging, random forest, and extra random trees models. With lowest oob error model, calculate mean score of balanced accuracy from cross validation with 5-fold stratified k fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-24T17:39:31.808017Z",
     "start_time": "2021-09-24T17:39:31.796497Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function for error measures\n",
    "def measure_error(y_true, y_pred, label=''):\n",
    "    return pd.Series({'accuracy':accuracy_score(y_true, y_pred),\n",
    "                      'precision': precision_score(y_true, y_pred, average='micro'),\n",
    "                      'recall': recall_score(y_true, y_pred, average='micro'),\n",
    "                      'balanced accuracy': balanced_accuracy_score(y_true, y_pred),\n",
    "                      'f1': f1_score(y_true, y_pred, average='micro')},\n",
    "                      name=label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Deicision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 348)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Base decision tree model to obtain gridsearch parameter\n",
    "dt = DecisionTreeClassifier()\n",
    "dt = dt.fit(X_data, y_data)\n",
    "dt.tree_.max_depth, len(dt.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_data {'max_depth': 6, 'max_features': 117} 0.784860431734883\n",
      "X_data_drop {'max_depth': 10, 'max_features': 139} 0.7560432083281073\n"
     ]
    }
   ],
   "source": [
    "# Gridsearch each dataset with stratified cross validation, check balanced accuracy\n",
    "for data_name, X_data in X_data_dict.items():\n",
    "    dtc = DecisionTreeClassifier()\n",
    "    GS_dtc = GridSearchCV(dtc,\n",
    "                          param_grid={\n",
    "                              'max_depth': range(1, dt.tree_.max_depth+1),\n",
    "                              'max_features': range(1, len(dt.feature_importances_)+1),\n",
    "                          },\n",
    "                          scoring='balanced_accuracy',\n",
    "                          refit=True,\n",
    "                          cv=StratifiedKFold(n_splits=5)\n",
    "                         )\n",
    "    GS_dtc.fit(X_data, y_data)\n",
    "    print(data_name, GS_dtc.best_params_, GS_dtc.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Bagging, Random Forest, Extra Random Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress warnings about too few trees from the early models\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_data</th>\n",
       "      <th>X_data_drop</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_trees</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15.0</th>\n",
       "      <td>0.135385</td>\n",
       "      <td>0.152308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20.0</th>\n",
       "      <td>0.130769</td>\n",
       "      <td>0.136923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30.0</th>\n",
       "      <td>0.124615</td>\n",
       "      <td>0.136923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40.0</th>\n",
       "      <td>0.115385</td>\n",
       "      <td>0.132308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50.0</th>\n",
       "      <td>0.115385</td>\n",
       "      <td>0.130769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100.0</th>\n",
       "      <td>0.107692</td>\n",
       "      <td>0.123077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150.0</th>\n",
       "      <td>0.106154</td>\n",
       "      <td>0.130769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200.0</th>\n",
       "      <td>0.106154</td>\n",
       "      <td>0.127692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300.0</th>\n",
       "      <td>0.104615</td>\n",
       "      <td>0.121538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400.0</th>\n",
       "      <td>0.103077</td>\n",
       "      <td>0.118462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500.0</th>\n",
       "      <td>0.103077</td>\n",
       "      <td>0.121538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           X_data  X_data_drop\n",
       "n_trees                       \n",
       "15.0     0.135385     0.152308\n",
       "20.0     0.130769     0.136923\n",
       "30.0     0.124615     0.136923\n",
       "40.0     0.115385     0.132308\n",
       "50.0     0.115385     0.130769\n",
       "100.0    0.107692     0.123077\n",
       "150.0    0.106154     0.130769\n",
       "200.0    0.106154     0.127692\n",
       "300.0    0.104615     0.121538\n",
       "400.0    0.103077     0.118462\n",
       "500.0    0.103077     0.121538"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check oob error with number of trees\n",
    "bc_oob_df = list()\n",
    "for data_name, X_data in X_data_dict.items():\n",
    "    bc = BaggingClassifier(oob_score=True, warm_start=False, random_state=20184757)\n",
    "    oob_list = list()\n",
    "    \n",
    "    for n_trees in [15, 20, 30, 40, 50, 100, 150, 200, 300, 400, 500]:\n",
    "        bc.set_params(n_estimators=n_trees)\n",
    "        bc.fit(X_data, y_data)\n",
    "        oob_error = 1 - bc.oob_score_\n",
    "        oob_list.append(pd.Series({'n_trees': n_trees, data_name: oob_error}))\n",
    "        \n",
    "    bc_oob = pd.concat(oob_list, axis=1).T.set_index('n_trees')\n",
    "    bc_oob_df.append(bc_oob)\n",
    "bc_oob_df = pd.concat(bc_oob_df, axis=1)\n",
    "bc_oob_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.760109466672241"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross validate (stratified) bagging best model\n",
    "bc = BaggingClassifier(n_estimators=400)\n",
    "np.mean(cross_val_score(bc, X_data_dict['X_data'], y_data, cv=StratifiedKFold(n_splits=5), scoring='balanced_accuracy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_data</th>\n",
       "      <th>X_data_drop</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_trees</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15.0</th>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.166154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20.0</th>\n",
       "      <td>0.121538</td>\n",
       "      <td>0.156923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30.0</th>\n",
       "      <td>0.127692</td>\n",
       "      <td>0.141538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40.0</th>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.129231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50.0</th>\n",
       "      <td>0.113846</td>\n",
       "      <td>0.129231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100.0</th>\n",
       "      <td>0.104615</td>\n",
       "      <td>0.127692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150.0</th>\n",
       "      <td>0.107692</td>\n",
       "      <td>0.123077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200.0</th>\n",
       "      <td>0.106154</td>\n",
       "      <td>0.124615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300.0</th>\n",
       "      <td>0.103077</td>\n",
       "      <td>0.129231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400.0</th>\n",
       "      <td>0.107692</td>\n",
       "      <td>0.129231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500.0</th>\n",
       "      <td>0.098462</td>\n",
       "      <td>0.124615</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           X_data  X_data_drop\n",
       "n_trees                       \n",
       "15.0     0.140000     0.166154\n",
       "20.0     0.121538     0.156923\n",
       "30.0     0.127692     0.141538\n",
       "40.0     0.120000     0.129231\n",
       "50.0     0.113846     0.129231\n",
       "100.0    0.104615     0.127692\n",
       "150.0    0.107692     0.123077\n",
       "200.0    0.106154     0.124615\n",
       "300.0    0.103077     0.129231\n",
       "400.0    0.107692     0.129231\n",
       "500.0    0.098462     0.124615"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check oob error with number of trees\n",
    "rfc_oob_df = list()\n",
    "for data_name, X_data in X_data_dict.items():\n",
    "    rfc = RandomForestClassifier(oob_score=True, warm_start=False, bootstrap=True, random_state=20184757)\n",
    "    oob_list = list()\n",
    "    \n",
    "    for n_trees in [15, 20, 30, 40, 50, 100, 150, 200, 300, 400, 500]:\n",
    "        rfc.set_params(n_estimators=n_trees)\n",
    "        rfc.fit(X_data, y_data)\n",
    "        oob_error = 1 - rfc.oob_score_\n",
    "        oob_list.append(pd.Series({'n_trees': n_trees, data_name: oob_error}))\n",
    "        \n",
    "    rfc_oob = pd.concat(oob_list, axis=1).T.set_index('n_trees')\n",
    "    rfc_oob_df.append(rfc_oob)\n",
    "rfc_oob_df = pd.concat(rfc_oob_df, axis=1)\n",
    "rfc_oob_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.744225302061123"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross validate (stratified) random forest best model\n",
    "rfc = RandomForestClassifier(n_estimators=500, bootstrap=True)\n",
    "np.mean(cross_val_score(rfc, X_data_dict['X_data'], y_data, cv=StratifiedKFold(n_splits=5), scoring='balanced_accuracy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra Random Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_data</th>\n",
       "      <th>X_data_drop</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_trees</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15.0</th>\n",
       "      <td>0.149231</td>\n",
       "      <td>0.206154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20.0</th>\n",
       "      <td>0.123077</td>\n",
       "      <td>0.186154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30.0</th>\n",
       "      <td>0.123077</td>\n",
       "      <td>0.164615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40.0</th>\n",
       "      <td>0.123077</td>\n",
       "      <td>0.164615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50.0</th>\n",
       "      <td>0.133846</td>\n",
       "      <td>0.155385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100.0</th>\n",
       "      <td>0.123077</td>\n",
       "      <td>0.146154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150.0</th>\n",
       "      <td>0.116923</td>\n",
       "      <td>0.143077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200.0</th>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.138462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300.0</th>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.136923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400.0</th>\n",
       "      <td>0.118462</td>\n",
       "      <td>0.140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500.0</th>\n",
       "      <td>0.121538</td>\n",
       "      <td>0.141538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           X_data  X_data_drop\n",
       "n_trees                       \n",
       "15.0     0.149231     0.206154\n",
       "20.0     0.123077     0.186154\n",
       "30.0     0.123077     0.164615\n",
       "40.0     0.123077     0.164615\n",
       "50.0     0.133846     0.155385\n",
       "100.0    0.123077     0.146154\n",
       "150.0    0.116923     0.143077\n",
       "200.0    0.120000     0.138462\n",
       "300.0    0.120000     0.136923\n",
       "400.0    0.118462     0.140000\n",
       "500.0    0.121538     0.141538"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check oob error with number of trees\n",
    "etc_oob_df = list()\n",
    "for data_name, X_data in X_data_dict.items():\n",
    "    etc = ExtraTreesClassifier(oob_score=True, warm_start=False, bootstrap=True, random_state=20184757)\n",
    "    oob_list = list()\n",
    "    \n",
    "    for n_trees in [15, 20, 30, 40, 50, 100, 150, 200, 300, 400, 500]:\n",
    "        etc.set_params(n_estimators=n_trees)\n",
    "        etc.fit(X_data, y_data)\n",
    "        oob_error = 1 - etc.oob_score_\n",
    "        oob_list.append(pd.Series({'n_trees': n_trees, data_name: oob_error}))\n",
    "        \n",
    "    etc_oob = pd.concat(oob_list, axis=1).T.set_index('n_trees')\n",
    "    etc_oob_df.append(etc_oob)\n",
    "etc_oob_df = pd.concat(etc_oob_df, axis=1)\n",
    "etc_oob_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6804979305154898"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross validate (stratified) extra random trees best model\n",
    "etc = ExtraTreesClassifier(n_estimators=400, bootstrap=True)\n",
    "np.mean(cross_val_score(etc, X_data_dict['X_data'], y_data, cv=StratifiedKFold(n_splits=5), scoring='balanced_accuracy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis \n",
    "\n",
    "* From above training code, select models which has highest balanced accuracy value\n",
    "* Print confusion matrix and various error measures including accuracy, precision, recall, balanced accuracy, f1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for best models, with whole data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[329,   3,   4],\n",
       "        [  4, 236,   0],\n",
       "        [ 12,   1,  61]]),\n",
       " accuracy             0.963077\n",
       " precision            0.963077\n",
       " recall               0.963077\n",
       " balanced accuracy    0.928941\n",
       " f1                   0.963077\n",
       " Name: , dtype: float64)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DT best model 1 (0.784860431734883)\n",
    "model = DecisionTreeClassifier(max_depth=6, max_features=117)\n",
    "model.fit(X_data_dict['X_data'], y_data)\n",
    "y_pred = model.predict(X_data_dict['X_data'])\n",
    "confusion_matrix(y_true=y_data, y_pred=y_pred), measure_error(y_true=y_data, y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[336,   0,   0],\n",
       "        [  0, 240,   0],\n",
       "        [  0,   0,  74]]),\n",
       " accuracy             1.0\n",
       " precision            1.0\n",
       " recall               1.0\n",
       " balanced accuracy    1.0\n",
       " f1                   1.0\n",
       " Name: , dtype: float64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DT best model 2 (0.760109466672241)\n",
    "model = BaggingClassifier(n_estimators=400)\n",
    "model.fit(X_data_dict['X_data'], y_data)\n",
    "y_pred = model.predict(X_data_dict['X_data'])\n",
    "confusion_matrix(y_true=y_data, y_pred=y_pred), measure_error(y_true=y_data, y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "name": "Linear_Regression_and_K_Nearest_Neighbors_Exercises-ANSWERS",
  "notebookId": 2125319687183902,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
